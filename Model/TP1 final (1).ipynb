{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMbJyUIZ_nfV"
   },
   "source": [
    "<h1><center> TP1 : Basic functions for Supervised Machine Learning. </center></h1>\n",
    "\n",
    "The deadline for report submission is Tuesday, November 10th 2020.\n",
    "\n",
    "Note: the goal of this first TP is to become familiar with 'sklearn' class in Python. In particular, we introduce most popular supervised learning algorithms. \n",
    "\n",
    "PART 1 is a list of commands that should be followed step by step. PART 2 is an open problem for which we are waiting for your creativity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ba95CyNW_nfW"
   },
   "source": [
    "## Imported packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MxR4ML8w_nfW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq5n9pys_nfb"
   },
   "source": [
    "#  PART 1 -- MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtknrKIq_nfb"
   },
   "source": [
    "In the first part of TP1 we pursue the following goals:\n",
    "1. Apply standard ML algorithms on a standard benchmark data\n",
    "2. Learn basic means of data visualizations\n",
    "3. Get familiar with sklearn's GridSearchCV and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx3BwJB7_nfc"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9prke3y_nfc"
   },
   "source": [
    "MNIST dataset consists of black and white images of hand-written digits from $0$ to $9$ of size $28 \\times 28$.\n",
    "In this exercise we will work with a small from the original MNIST dataset. \n",
    "\n",
    "If you are interested in the whole dataset, execute the following commands\n",
    "```python\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=custom_data_home)\n",
    "```\n",
    "\n",
    "Hence, the observations $(X_1, Y_1), \\ldots, (X_n, Y_n)$ are such that $X_i \\in \\mathbb{R}^{784}$ and $Y_i \\in \\{0, \\ldots, 9\\}$. To be more precise, each component of vector $X_i$ is a number between $0$ and $255$, which signifies the intensity of black color.\n",
    "\n",
    "The initial goal is to build a classifier $\\hat g$, which receives a new image $X$ and outputs the number that is present on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b87gOvG3_nfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data contains: 2000 samples of dimension 784\n",
      "Test data contains: 200 samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/mnist1_features_train.npy', allow_pickle=True)\n",
    "y_train = np.load('data/mnist1_labels_train.npy', allow_pickle=True)\n",
    "X_test = np.load('data/mnist1_features_test.npy', allow_pickle=True)\n",
    "y_test = np.load('data/mnist1_labels_test.npy', allow_pickle=True)\n",
    "\n",
    "n_samples, n_features = X_train.shape # extract dimensions of the design matrix\n",
    "print('Train data contains: {} samples of dimension {}'.format(n_samples, n_features))\n",
    "print('Test data contains: {} samples'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9d6tTya_nfg"
   },
   "source": [
    "## Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyU0Vx5l_nfg"
   },
   "source": [
    "Since each observation is actually an image, we can visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rJip4ApA_nfh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(1, 10)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "images_and_labels = list(zip(X_train, y_train)) \n",
    "for ax, (image, label) in zip(axes, images_and_labels[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('{}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZZn3hTP9_nfk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s in the train dataset is 196\n",
      "Number of 1s in the train dataset is 226\n",
      "Number of 2s in the train dataset is 214\n",
      "Number of 3s in the train dataset is 211\n",
      "Number of 4s in the train dataset is 187\n",
      "Number of 5s in the train dataset is 179\n",
      "Number of 6s in the train dataset is 175\n",
      "Number of 7s in the train dataset is 225\n",
      "Number of 8s in the train dataset is 186\n",
      "Number of 9s in the train dataset is 201\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Number of {}s in the train dataset is {}'.format(i, np.sum([y_train == str(i)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_labels={ }\n",
    "for i in range(10):\n",
    "    num_labels[i] = np.sum(y_train==str(i))\n",
    "x,y  = zip(*num_labels.items())    \n",
    "\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9dWeV7G_nfm"
   },
   "source": [
    "From the above we conclude that the dataset is rather balanced, that is, each class contains similar amount of observations. The rarest class is $y = 6$ with $175$ examples and the most common class is $y = 2$ with $226$ examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glcFsx7k_nfn"
   },
   "source": [
    "## Cross-validation with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1WiDMZj_nfo"
   },
   "source": [
    "\n",
    "**Question:** Explain in your report what happens when we run \n",
    "```python\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "\n",
    "What is the complexity for each of the three following cases? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>We fit using a GridSearchCv KNeighborsClassifier. clf is the name of the object wich allows to do cross validation based on our knn classifier. We run a cross validatoin with cv=3; we divide (Xtrain, Ytrain) into 3 parts. Then we applied knn algorithm on train of the first part (with k from 1 to 5), and we estimate the error. We repeat it on the second and third parts. The fit method fits the training dataset as features X and labels Y into a model.<br>\n",
    "- <i>The cost of an algorithm depends on the number of elementary operations (arithmetic or logical) as well as on the number of assignments necessary for its execution. With the notations n= number of training examples, d=number of dimensions of the data, k=number of neighbors : Knn’s complexity is o(knd), SVC’s complexity is o(n2) and Logistic regression’s complexity is o(nd)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UU7t7Xyo_nfo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'n_neighbors': 1}\n",
      "Best classification accuracy in train is: 0.891497944721333\n",
      "Classification accuracy on test is: 0.875\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV with kNN : a simple baseline\n",
    "knn = KNeighborsClassifier() # defining classifier\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5]} # defining parameter space\n",
    "clf = GridSearchCV(knn, parameters, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htZ5-0Yt_nfr"
   },
   "source": [
    "**Question:** What is the test accuracy? What would be the accuracy of random guess?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>The test accuracy is given by running this command : clf.score(Xtest,ytest)). It’s equal to 0.875. The accuracy of random guess is 1/10, it follows an uniform distribution over 10 classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        22\n",
      "           1       0.90      1.00      0.95        26\n",
      "           2       1.00      0.88      0.93        16\n",
      "           3       0.95      0.83      0.88        23\n",
      "           4       0.81      0.85      0.83        20\n",
      "           5       0.58      0.70      0.64        10\n",
      "           6       0.92      0.96      0.94        24\n",
      "           7       0.83      0.94      0.88        16\n",
      "           8       0.88      0.82      0.85        17\n",
      "           9       0.83      0.73      0.78        26\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.86      0.87      0.86       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "Confusion matrix\n",
      "By definition a confusion matrix  is such that  is equal to the number of observations known to be in group  and predicted to be in group .\n",
      "[[21  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  2  0  0  0  0]\n",
      " [ 0  0  0 19  0  2  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 0  0  0  0  1  7  1  0  1  0]\n",
      " [ 0  0  0  0  0  1 23  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 14  1]\n",
      " [ 1  1  0  0  2  0  0  3  0 19]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels= clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predicted_labels,labels=clf.classes_)\n",
    "\n",
    "print(classification_report(y_test, predicted_labels, labels=clf.classes_))\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(\"By definition a confusion matrix  is such that  is equal to the number of observations known to be in group  and predicted to be in group .\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLc-AQ3d_nfs"
   },
   "source": [
    "**Question:** What is ``` LinearSVC()``` classifier? Which kernel are we using? What is ```C```? (this is a tricky question, try to find the answer online)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>Linear Support Vector Classification is similar to Support Vector Classification with parameter ker- nel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.<br>\n",
    "- <i>This class supports both dense and sparse input and the multiclass support is handled according to a one- vs-the-rest scheme.<br>\n",
    "- <i>C is the Regularization parameter. C is like a Lasso penalization, in that it adds biais and it removes variance in order to generalize the model. The margins telles us the tolerance of how many points will be within the margin. If C increases, the margins decreases and then we have overtfitting’s risk. In addition, we must normalize our data before the regularization so that we can calculate comparable distances. The strength of the regularization is inversely proportional to C. It must be strictly positive. We represented the relation between C and the margins in figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzXdFHVr_nfs"
   },
   "source": [
    "**Question:** What is the outcome of ```np.logspace(-8, 8, 17, base=2)```? More generally, what is the ourcome of ```np.logspace(-a, b, k, base=m)```?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ```python\n",
    "  array([3.90625e-03, 7.81250e-03, 1.56250e-02, 3.12500e-02, 6.25000e-02,\n",
    "       1.25000e-01, 2.50000e-01, 5.00000e-01, 1.00000e+00, 2.00000e+00,\n",
    "       4.00000e+00, 8.00000e+00, 1.60000e+01, 3.20000e+01, 6.40000e+01,\n",
    "       1.28000e+02, 2.56000e+02])\n",
    "     ```\n",
    "    \n",
    "- np.logspace(−a, b, k, base = m) Return numbers spaced evenly on a log scale. -a = base, start is the starting value of the sequence. b = base, stop is the final value of the sequence, unless endpoint is False. In that case, num + 1 values are spaced over the interval in log-space, of which all but the last (a sequence of length num) are returned.\n",
    "    - **k = Number of samples to generate.** Default is 50.\n",
    "    - **base = m** : The base of the log space. \n",
    "    - The step size between the elements in **$ln(samples) / ln(base) ($or $log_b(samples))$** is uniform. Default is 10.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "12I4xqY3_nft"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'C': 0.00390625}\n",
      "Best classification accuracy in train is: 0.8095074084579332\n",
      "Classification accuracy on test is: 0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "svc = LinearSVC(max_iter=5000)\n",
    "parameters2 = {'C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf2 = GridSearchCV(svc, parameters2, cv=3)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf2.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf2.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcuJPjjq_nfv"
   },
   "source": [
    "**Question** What is the meaning of the warnings? What is the parameter responsible for its appearence?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>It means that the algorithm does not converge using each of the 17 regularization parameters C, because the number of iterations is too low, we could not resolve a convex optimization problem.<br>\n",
    "- <i>The parameter responsible is maxiter (number of iterations to reach our extremum) in the funtion SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dgjoxWpW_nfw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 0.015625}\n",
      "Best classification accuracy in train is: 0.863002432717575\n",
      "Classification accuracy on test is: 0.84\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier + Pipeline\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters3 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf3 = GridSearchCV(pipe, parameters3, cv=3)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf3.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf3.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VdXZthv_nfy"
   },
   "source": [
    "**Question:** What did we change with respect to the previous run of ```LinearSVC()```?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>We used the pipeline (scaler MaxAbsScaler) to transform the dataset, before using the svm model. The transformation scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Explain what happens if we execute\n",
    "```python\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.predict(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>The fit function is executed with default params. The features are first transformed using the pipeline MaxAbsScaler(), and after we considered the Linearsvc model.<br>\n",
    "- <i>The predict part  won't work because it only takes one parameter\n",
    "    ``` python\n",
    "    pipe.fit(X_train,y_train)\n",
    "    pipe.predict(X_test)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4', '1', '6', '5', '3', '4', '1', '3', '3', '1', '0', '6', '3',\n",
       "       '4', '9', '7', '6', '4', '1', '6', '1', '4', '3', '8', '9', '4',\n",
       "       '7', '8', '1', '1', '5', '6', '1', '4', '0', '2', '0', '9', '9',\n",
       "       '6', '2', '4', '6', '4', '9', '8', '7', '7', '0', '9', '4', '6',\n",
       "       '9', '7', '5', '2', '2', '7', '1', '6', '5', '4', '2', '8', '9',\n",
       "       '6', '3', '2', '8', '1', '7', '0', '1', '3', '2', '0', '9', '0',\n",
       "       '0', '0', '1', '0', '8', '7', '9', '9', '2', '1', '8', '9', '3',\n",
       "       '1', '5', '1', '3', '1', '3', '0', '8', '7', '0', '6', '5', '9',\n",
       "       '4', '0', '2', '5', '6', '9', '7', '5', '6', '3', '9', '7', '9',\n",
       "       '0', '9', '3', '9', '1', '3', '1', '3', '6', '1', '3', '8', '8',\n",
       "       '2', '9', '9', '6', '2', '7', '4', '3', '9', '2', '7', '0', '8',\n",
       "       '1', '2', '3', '6', '0', '8', '1', '5', '0', '0', '3', '0', '4',\n",
       "       '3', '1', '3', '9', '0', '4', '3', '9', '4', '8', '4', '7', '3',\n",
       "       '0', '9', '5', '8', '4', '6', '6', '3', '0', '4', '7', '0', '3',\n",
       "       '1', '8', '7', '8', '0', '4', '9', '6', '7', '1', '1', '2', '2',\n",
       "       '3', '6', '6', '2', '0'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)\n",
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Filtering future warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OYq25hM0_nfy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'logreg__C': 0.0078125}\n",
      "Best classification accuracy in train is: 0.8705039372205788\n",
      "Classification accuracy on test is: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(solver='lbfgs',max_iter=5000))])\n",
    "parameters4 = {'logreg__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf4 = GridSearchCV(pipe, parameters4, cv=3)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JThSDL3_nf1"
   },
   "source": [
    "**Question:** what is the difference between ```StandardScaler()``` and ```MaxAbsMaxAbsScalerler()```? What are other scaling options available in ```sklearn```?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <i>StandardScaler standardize features by removing the mean and scaling to unit variance while MaxAbsScaler does not shift/center the data, and thus does not destroy any sparsity. The others scaling options are MinMaxScaler, RobustScaler and PowerTransformer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMhXo65R_nf1"
   },
   "source": [
    "**Question:** using the previous code as an example achieve test accuracy $\\geq 0.9$. You can use any method from sklearn package. Give a mathematical description of the selected method. Explain the range of considered hyperparamers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the random forest method. Its consists in created a large number of classification trees. The label of a new individual whose features are X, will be determined by a majority vote.\n",
    "\n",
    "#### Mathematical description:\n",
    "For $B$ in n_estimators : \n",
    "1. For $b=1$ to $B$:\n",
    "    1. Draw a bootstrap sample $Z^*$ of size $N$ from X_train\n",
    "    2. Grow a random forest tress $T_b$ to the bootstrapped data, by recursively repeating the following steps for each terminal node of the tree, until the minimum node size $n_{min}$ is reached\n",
    "        1. Select $p$ variables randomly from the 784 variables\n",
    "        2. Pick the best variable/split-point among the $p$/\n",
    "        3. Split the node into two daughter nodes\n",
    "2. Output the ensemble trees $\\{T_b\\}^B_1$       \n",
    "\n",
    "The prediction is then made using majority vote: \n",
    "\n",
    "Let $C_b(x)$ be the class prediction of the bth random-forest tree.\n",
    "\n",
    "> Then $C_{rf}^B(b)= majority\\ vote \\{C_b(x)\\}^B_1$\n",
    "\n",
    "\n",
    "\n",
    "We chose a number of trees between 800 and 1300 because the more trees we have, the lesser the variance. We start at 800 trees because 784 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'rf__n_estimators': 800}\n",
      "Best classification accuracy in train is: 0.9155032093562827\n",
      "Classification accuracy on test is: 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('rf', RandomForestClassifier())])\n",
    "parameters5 = {'rf__n_estimators': [800,900,1000,1100, 1200, 1300]} # defining parameter space\n",
    "clf5 = GridSearchCV(pipe, parameters5, cv=3)\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf5.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf5.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf5.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        22\n",
      "           1       0.93      1.00      0.96        26\n",
      "           2       0.93      0.88      0.90        16\n",
      "           3       0.95      0.91      0.93        23\n",
      "           4       0.86      0.95      0.90        20\n",
      "           5       0.82      0.90      0.86        10\n",
      "           6       1.00      0.83      0.91        24\n",
      "           7       0.94      1.00      0.97        16\n",
      "           8       0.94      0.88      0.91        17\n",
      "           9       0.92      0.88      0.90        26\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.92      0.92      0.92       200\n",
      "weighted avg       0.93      0.93      0.92       200\n",
      "\n",
      "Confusion matrix\n",
      "By definition a confusion matrix  is such that  is equal to the number of observations known to be in group  and predicted to be in group .\n",
      "[[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 14  0  1  0  0  0  0  0]\n",
      " [ 0  0  0 21  0  1  0  0  0  1]\n",
      " [ 0  0  0  0 19  0  0  0  0  1]\n",
      " [ 0  0  0  0  1  9  0  0  0  0]\n",
      " [ 1  1  1  0  0  1 20  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 16  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 15  0]\n",
      " [ 0  0  0  0  1  0  0  1  1 23]]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels= clf5.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predicted_labels,labels=clf.classes_)\n",
    "\n",
    "print(classification_report(y_test, predicted_labels, labels=clf.classes_))\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(\"By definition a confusion matrix  is such that  is equal to the number of observations known to be in group  and predicted to be in group .\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSLA-W8f_nf2"
   },
   "source": [
    "## Visualizing errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6WsLRVj_nf2"
   },
   "source": [
    "Some ```sklearn``` methods are able to output probabilities ```predict_proba(X_test)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIy5Qq_M_nf5"
   },
   "source": [
    "**Question** There is a mistake in the following chunk of code. Fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DTo8GP1y_nf5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(2, 4)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "y_pred = clf4.predict(X_test)\n",
    "j = 0 # Index which iterates over plots\n",
    "for true_label, pred_label, image in list(zip(y_test, y_pred, X_test)):\n",
    "    if j == 4: # We only want to look at 4 first mistakes\n",
    "        break\n",
    "    if true_label != pred_label:\n",
    "        # Plotting predicted probabilities\n",
    "        axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1))[0]) \n",
    "        axes[1, j].set_xticks(np.arange(10))\n",
    "        axes[1, j].set_yticks([])\n",
    "        \n",
    "        # Plotting the image\n",
    "        axes[0, j].imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        axes[0, j].set_xticks([])\n",
    "        axes[0, j].set_yticks([])\n",
    "        axes[0, j].set_title('Predicted {}'.format(pred_label))\n",
    "        j += 1\n",
    "        \n",
    "#         plt.xticks(x, ('Bill', 'Fred', 'Mary', 'Sue'))\n",
    "#         axex[1, j].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCfSgtV__nf8"
   },
   "source": [
    "## Changing the Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OR48R9n_nf9"
   },
   "source": [
    "It often happens that the accuracy is not the right way to evaluate the performance. ```sklearn``` has a large variety of other metrics both in classification and regression. See https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "Here we want to understand how to change the cross-validation metric with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZRw0iEUD_nf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 0.015625}\n",
      "Best Balanced accuracy in train is: 0.8612334093654231\n",
      "Balanced accuracy on test is: 0.825627008328415\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier + Pipeline + New score function\n",
    "\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters4 = {'svc__C': np.logspace(-8, 8, 5, base=2)} # defining parameter space\n",
    "balanced_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "clf4 = GridSearchCV(pipe, parameters3, cv=3, scoring=balanced_scorer)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best Balanced accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Balanced accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwPxbFX2_nf_"
   },
   "source": [
    "**Question:** What is ```balanced_accuracy_score```? Write its mathematical mathematical description.\n",
    "\n",
    "* The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "* \n",
    "Σ True positive\n",
    "/\n",
    "Σ Condition positive ( true positive + false negative)\n",
    "\n",
    "* The best value is 1 and the worst value is 0 when adjusted=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.<br><br>\n",
    "\n",
    "<i>Σ True positive/ Σ Condition positive ( true positive + false negative)<br><br>\n",
    "\n",
    "<i>The best value is 1 and the worst value is 0 when adjusted=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxVZkbfb_ngA"
   },
   "source": [
    "Sometimes it is important to look at the confusion matrix of the prediction.\n",
    "\n",
    "**Question:** What is the confusion matrix? What are the conclusions that we can draw from the ```confusion_matrix(y_test, clf4.predict(X_test))```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BNZlMVno_ngA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 24  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 14  1  1  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  3  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 1  0  0  1  0  6  0  1  0  1]\n",
      " [ 1  2  1  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  2  0  1  0  3  0  0 11  0]\n",
      " [ 0  0  0  0  2  0  0  2  1 21]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, clf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD8zfpwi_ngC"
   },
   "source": [
    "# PART 2 -- Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsQ8-Nyq_ngD"
   },
   "source": [
    "The data that we have contains images with $10$ classes. Normally, accuracy is a reasonable choice of the loss function to be optimized, but in this problem we *really* do not like when digits from $\\{5, 6, 7, 8, 9\\}$ are predicted to be from $\\{0, 1, 2, 3, 4\\}$.\n",
    "\n",
    "**Question:** Propose a loss function that would address our needs. Explain your choice.\n",
    "\n",
    "\n",
    "**Question:** Following above examples, make an ML pipeline that uses *your* loss function and finds appropriate classifiers.\n",
    "\n",
    "When writing your report on this part, include:\n",
    "   1. description of your loss function\n",
    "   2. description of the pipeline\n",
    "   3. description of the algorithms that you used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "##  Our solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test our custom loss function, we decided to use the whole mnist dataset\n",
    "\n",
    "First, we import the full mnist dataset from the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 785 entries, col_1 to y\n",
      "dtypes: int64(785)\n",
      "memory usage: 419.2 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"mnist.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:,:-1].to_numpy()\n",
    "Y= df.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the training set and test set with a test size of **20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data contains: 56000 samples of dimension 784\n",
      "Test data contains: 14000 samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "print('Train data contains: {} samples of dimension {}'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Test data contains: {} samples'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to create our custom loss function.\n",
    "\n",
    "We made it very simple. We created a function that takes in two parameters: **TrueLabel and Predictedlabel**  :\n",
    "\n",
    "> For any number between {5-9} predicted with a label in {0-4} : adds 10 points to the loss score, Any other error adds 1.\n",
    "\n",
    "This penalization insures that the parameters of the model are chosen accordingly. \n",
    "\n",
    "\n",
    "The dataset provided in the assignment was not big enough to see the impact of this change. So we downloaded the full mnist dataset, and it worked !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_func(y_true, y_pred):\n",
    "    \"\"\" The custom loss funciton penalizing 10x if the predicted label is in {0-4} \n",
    "    and the true label is in {5-9}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy array\n",
    "        The true labels\n",
    "    y_pred : numpy array\n",
    "        predicted labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        float \n",
    "            total Score float\n",
    "    \"\"\"\n",
    "    score=np.zeros(len(y_true))\n",
    "    for i in range(len(y_true)):\n",
    "        x,y = y_true[i],y_pred[i]\n",
    "        if x >=5 and y<=4:\n",
    "            score[i]=10\n",
    "        elif x-y != 0 :\n",
    "            score[i]=1\n",
    "    return np.sum(score)\n",
    "\n",
    "\n",
    "\n",
    "def count_loss(y_true, y_pred):\n",
    "    \"\"\" Counts the number of 'big' errors ie : labels predicted in {0-4} \n",
    "     where true label is in {5-9}\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : numpy array\n",
    "        The true labels\n",
    "    y_pred : numpy array\n",
    "        predicted labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        int \n",
    "            total number of 'big' errors\n",
    "    \"\"\"\n",
    "        \n",
    "    y_true= np.asarray([int(i) for i in y_true])\n",
    "    y_pred= np.asarray([int(i) for i in y_pred])\n",
    "    count=0\n",
    "    for i in range(len(y_true)):\n",
    "        x,y = y_true[i],y_pred[i]\n",
    "        if x in list(range(5,10)) and y in list(range(0,5)):\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('rf', RandomForestClassifier())])\n",
    "parameters5 = {'rf__n_estimators': [1200]} # defining parameter space\n",
    "\n",
    "custom_scorer = make_scorer(custom_loss_func,greater_is_better=False)\n",
    "\n",
    "clf5 = GridSearchCV(pipe, parameters5, cv=3, scoring=custom_scorer)\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf5.best_params_))\n",
    "print('Best accuracy in train is: {}'.format(clf5.best_score_))\n",
    "print('Accuracy in test is: {}'.format(clf5.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf5, X_test, y_test)  \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing to the 'normal' loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('rf', RandomForestClassifier())])\n",
    "parameters55 = {'rf__n_estimators': [1200]} # defining parameter space\n",
    "\n",
    "\n",
    "clf55 = GridSearchCV(pipe, parameters5, cv=3)\n",
    "clf55.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf55.best_params_))\n",
    "print('Best accuracy in train is: {}'.format(clf55.best_score_))\n",
    "print('Accuracy in test is: {}'.format(clf55.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf55, X_test, y_test)  \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_loss(y_test,clf55.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "name": "TP1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
